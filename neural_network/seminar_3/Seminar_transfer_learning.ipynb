{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1WF-aVfUn4bfqvGPqXmlOUdvYNdVRVHE0","timestamp":1605651036736},{"file_id":"1DSl6Go23Zfn9qu7ArDN_uA9P1K4JQTHG","timestamp":1605388432129}],"collapsed_sections":["99LAkQNVZV5Y"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XgbimpoMZV5F"},"source":["<p style=\"align: center;\"><img src=\"https://static.tildacdn.com/tild6636-3531-4239-b465-376364646465/Deep_Learning_School.png\", width=550, height=300></p>\n","\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>\n","\n","---\n","\n","<h2 style=\"text-align: center;\"><b>Transfer Learning</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"-nVLftxNZV5H"},"source":["Как Вы уже знаете в современных задачах обработки изображений, будь то задача обнаружения объектов, задача распознавания образов, задача (семантической) сегментации, задача классификации изображений и другие, всё чаще используют **свёрточные нейросети** (*Convolutional Neural Networks*, *CNN*)."]},{"cell_type":"markdown","metadata":{"id":"LA5ixc_nZV5H"},"source":["Они показывают очень хорошие результаты, за ними стоит как [математический аппарат](https://stats.stackexchange.com/questions/269854/are-there-mathematical-reasons-for-convolution-in-neural-networks-beyond-expedie), так и эвристики, полученные опытным путём."]},{"cell_type":"markdown","metadata":{"id":"AUH-Q7FuZV5I"},"source":["В данном задании Вам предстоит познакомиться с архитектурами *AlexNet*, *VGG* и *Inception* и для каждой из этих моделей использовать технику **Transfer Learning**.  \n","\n","* **Transfer Learning** - это процесс дообучения на **новых данных** какой-либо нейросети, уже обученной до этого на других данных, обычно на каком-нибудь хорошем, большом (миллионы картинок) датасете (например, [ImageNet](http://www.image-net.org/) ~ 14 млн картинок)."]},{"cell_type":"markdown","metadata":{"id":"oaiyKxA7Sgvf"},"source":["<h2 style=\"text-align: center;\"><b>AlexNet</b></h2>"]},{"cell_type":"markdown","metadata":{"id":"7nFB2hnISgvj"},"source":["**AlexNet** - нейронная сеть, которая победила в ILSVRC (соревнование по классификации картинок из ImageNet) в 2012 году и стала основой для многих других архитектур. Впервые она была представлена в статье  “ImageNet Classification with Deep Convolutional Neural Networks”, над которой работал Джоффри Хинтон - человек, которого многие называют отцом современного computer vision.\n","\n","Архитектура описана на картинке ниже"]},{"cell_type":"markdown","metadata":{"id":"w-Hj_RLcSgvm"},"source":["<img src=\"https://www.learnopencv.com/wp-content/uploads/2018/05/AlexNet-1.png\">"]},{"cell_type":"markdown","metadata":{"id":"Y4zmFA6QSgvq"},"source":["**AlexNet** состоит из 5 **сверточных** слоев, 3 **MaxPool** слоев и 2 **FullyConnected** слоев в конце. Обратите внимание, что в последнем пулинг слое окна, из которых берется максимум, пересекаются за счет того, что *stride*=2. Это изменение по сравнению с традиционным пулингом помогло снизить ошибку на 0.4%.\n","\n","По сути **AlexNet** это самая базовая архитектура для сверточной сети после LeNet, которую мы уже писали на предыдущем занятии."]},{"cell_type":"markdown","metadata":{"id":"L5jQNFS5Sgvv"},"source":["<h2 style=\"text-align: center;\"><b>VGG</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"KPhsK5U2Sgvy"},"source":["Один **сверточный** слой с фильтром 5$\\times$5 можно заменить двумя подряд идущими слоями с фильтрами размером 3$\\times$3, так как **воспринимаемая область** картинки у них будет одинаковой. При этом уменьшиться количество параметров, поэтому такую сеть будет легче обучать.\n","\n","На момент создания VGG люди уже заметили, что чем больше слоев в нейросети, тем выше ее точность. Заменяя большие фильтры на несколько фильтров 3$\\times$3 исследователи получили глубокую нейросеть с меньшим количеством параметров. Архитектура VGG-16 (версии VGG с 16 слоями) представлена на картинке ниже:\n"]},{"cell_type":"markdown","metadata":{"id":"u5Fwng6XSgv3"},"source":["<img src=\"https://cdn-images-1.medium.com/max/1040/1*0Tk4JclhGOCR_uLe6RKvUQ.png\">"]},{"cell_type":"markdown","metadata":{"id":"8naUWATeSgv6"},"source":["Когда говорят **VGG**, то чаще всего имеют ввиду **VGG-16** или **VGG-19**. Более глубоких версий **VGG** нет, так как после 19 слоев точность начинает падать.\n","\n","Чтобы добиться высоких результатов в соревновании при обучении и валидации нейросети использовались дополнительные премы, подробнее о которых можно прочитать в [статье на Medium](https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11)."]},{"cell_type":"markdown","metadata":{"id":"EAjLsFn2Sgv8"},"source":["\n","<h2 style=\"text-align: center;\"><b>Inception v1</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"kVLsNug8SgwB"},"source":["### Рассмотрим идею, которая подтолкнула исследователей к созданию этой архитектуры.\n","\n","Площадь, которую занимает классифицируемый объект, может очень сильно отличаться. Пример на картинке ниже:"]},{"cell_type":"markdown","metadata":{"id":"prERHawrSgwD"},"source":["<img src=\"https://cdn-images-1.medium.com/max/1040/1*aBdPBGAeta-_AM4aEyqeTQ.jpeg\">"]},{"cell_type":"markdown","metadata":{"id":"QoPk-Gs7SgwF"},"source":["* Для извлечения информации с большой площади лучше всего подходят **большие** фильтры, и наоборот для маленьких объектов лучше **маленькие** фильтры.\n","* Глубокие нейронные сети намного сложнее обучать: в них появляется проблема **затухания градиента** и они **переобучаются**.\n","Чтобы решить первую проблему исследователи придумали **Incepton** модуль, который применяет фильтры разного размера и затем склеивает полученные каналы. При этом извлекается как информация из больших объектов, так и из маленьких. Простейшая реализация модуля выглядит так:\n","<img src=\"https://cdn-images-1.medium.com/max/1040/1*DKjGRDd_lJeUfVlY50ojOA.png\">"]},{"cell_type":"markdown","metadata":{"id":"fhUHlhcdSgwJ"},"source":["Реализацию можно сделать более эффективной, если сначала уменьшить количество каналов с помощью **сверточного слоя** 1$\\times$1 и лишь затем применить **слой** с фильтрами 5$\\times$5. Сокращение вычислений происходит за счет того, что мы сначала **уменьшаем размерность** данных и лишь затем преобразовываем их. Продвинутая реализация:\n","<img src=\"https://cdn-images-1.medium.com/max/1040/1*U_McJnp7Fnif-lw9iIC5Bw.png\">"]},{"cell_type":"markdown","metadata":{"id":"LYUeTuXWSgwL"},"source":["Сеть состоит из **корня** (нескольких сверточных слоев) и **Inception** модулей идущих за ним. Оранжевым прямоугольников выделен корень, а фиолетовыми - **вспомогательные классификаторы**. Именно они помогают бороться со второй проблемой, которую мы упомянули ранее. Наша функция потерь - взвешенная сумма **LogLoss** на двух **вспомогательных классификаторах** и **основном** в конце нейронной сети.\n","<img src=\"https://cdn-images-1.medium.com/max/1040/1*uW81y16b-ptBDV8SIT1beQ.png\">"]},{"cell_type":"markdown","metadata":{"id":"mkJw0QkcSgwN"},"source":["После Inception v1 были представлены 2, 3 и 4 версии, пррочитать о которых вы можете  в [статье на Medium](https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202).\n","\n","Однако сейчас научились иначе бороться с затуханием градиентов с помощью **residual conncection**. Это позволило увеличить число слоев в нейронной сети.\n","\n","![](https://i.imgur.com/XwcnU5x.png)"]},{"cell_type":"markdown","metadata":{"id":"bx9ZdMmMZV5I"},"source":["<h2 style=\"text-align: center;\"><b>Transfer Learning</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"j-EtKIoMZV5J"},"source":["Теперь мы перейдем к тому, как можно использовать уже обученные нейросети, чтобы ускорить свою работу.\n","\n","Давайте вспомним общую архитектуру CNN:"]},{"cell_type":"markdown","metadata":{"id":"XWER66eyZV5K"},"source":["<img src=\"https://drive.google.com/uc?id=14pApKqQjnmWMXazY0HHjREn9rI9uwCQg\">"]},{"cell_type":"markdown","metadata":{"id":"bihUjSwGZV5L"},"source":["С помощью операций *свёртки (convolution)* и *пулинга (pooling)* всё, что расположено до этапа *classification*, по сути **извлекает признаки из объектов, подающихся на вход** (картинок, в данном случае). То есть вместо того, чтобы самим пытаться как-то описать картинки для хорошей работы классификатора, мы предоставляем заняться этим нейросети (обучая её методом обратного распространения ошибки ([лекция 4](https://www.youtube.com/watch?v=HZDOhHAg5_g)))."]},{"cell_type":"markdown","metadata":{"id":"H5JCuydFZV5O"},"source":["Представим теперь, что eсть свой набор данных, и Вы хотите научить сеть классифицировать объекты из Вашей выборки.  \n"]},{"cell_type":"markdown","metadata":{"id":"gEoe0qi_ZV5O"},"source":["Надеемся, что теперь Вам стало понятнее, как обучать крутые сети на новых данных."]},{"cell_type":"markdown","metadata":{"id":"CU8jKks8ZV5P"},"source":["<h2 style=\"text-align: center;\"><b>Переходим к практике</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"JyvXMfhZZV5Q"},"source":["<p style=\"text-align: center;\"><i>(основано на http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)</i></p>"]},{"cell_type":"markdown","metadata":{"id":"6XFlfXQsZV5R"},"source":["Мы будем пользоваться библиотекой PyTorch. Если Вы её ещё не установили, то вот [инструкция на Wiki по установке PyTorch](https://github.com/deepmipt/dlschl/wiki/%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%86%D0%B8%D1%8F-%D0%BF%D0%BE-%D1%83%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BA%D0%B5-PyTorch)."]},{"cell_type":"code","metadata":{"id":"3xF5zpbFgkIp"},"source":["!pip install -q torchvision catalyst"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l2sTUHmNZV5S"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import time\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"weT3x9DQZV5X"},"source":["### В чём состоит задание"]},{"cell_type":"markdown","metadata":{"id":"F8paFz_5ZV5Y"},"source":["Вам предстоит попробовать использовать  типа архитектур свёрточных нейросетей - **AlexNet (сделано за Вас в примере), VGG16, Inception_v3** - как *Feature Extractor*, с помощью *Fine Tuning* и *\"из коробки\"*.\n","\n","**Для каждого пункта нужно:**\n","- вывести график loss'а на обучающей и на валидационной выборке\n","- вывести качество модели (accuracy)"]},{"cell_type":"markdown","metadata":{"id":"99LAkQNVZV5Y"},"source":["### Данные  \n","\n","В данном задании используются сети (из библиотеки **torchvision**), предобученные на датасете ImageNet.  \n","В качестве новых данных будет датасет Меравьи vs Пчёлы, Вам нужно скачать его отсюда: **[Муравьи vs Пчёлы](https://download.pytorch.org/tutorial/hymenoptera_data.zip)**, *являющийся частью датасета ImageNet*. В нём 400 картинок, ~250 обучение и ~150 валидация (тест)."]},{"cell_type":"markdown","metadata":{"id":"8gGQA6CbZV5Z"},"source":["### Функции для отрисовки и обучения модели:"]},{"cell_type":"markdown","metadata":{"id":"LnoL3STNZV5a"},"source":["* Загрузим данные:"]},{"cell_type":"code","metadata":{"id":"v5iKptyqo7hv"},"source":["!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n","!unzip hymenoptera_data.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lKZZSUYZV5b"},"source":["# Преобразование обучающих данных для расширения обучающей выборки и её нормализация\n","# Для валидационной (тестовой) выборки только нормализация\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(244),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(244),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","# папка с данными. Если запускаете в колабе, нужно скопировать данные к себе в директорию и примонтировать диск. Если запускаете локально -- просто скачайте данные\n","data_dir = './hymenoptera_data'\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'val']}\n","# специальный класс для загрузки данных в виде батчей\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    image_datasets[\"train\"], batch_size=32,\n","    shuffle=True\n",")\n","val_dataloader = torch.utils.data.DataLoader(\n","    image_datasets[\"val\"], batch_size=128\n",")\n","\n","loaders = {\n","    \"train\": train_dataloader,\n","    \"valid\": val_dataloader\n","}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = image_datasets['train'].classes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"03FqarW9ZV5e"},"source":["Размеры обучающей и валидационной выборок:"]},{"cell_type":"code","metadata":{"id":"MxjRd-5OZV5f"},"source":["print(dataset_sizes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GXqEVA1ZZV5m"},"source":["* Посмотрим на картинки из датасета:"]},{"cell_type":"code","metadata":{"id":"wQG2_RrvZV5n"},"source":["from matplotlib import pyplot as plt\n","\n","def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.figure(figsize=(15, 12))\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)\n","\n","\n","# Получим 1 батч (картнки-метки) из обучающей выборки\n","inputs, classes = next(iter(loaders['train']))\n","\n","# Расположим картинки рядом\n","out = torchvision.utils.make_grid(inputs)\n","\n","imshow(out, title=[class_names[x] for x in classes])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KqOOeBFpZV6T"},"source":["image_datasets[\"train\"][0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6exRIPRbSgzS"},"source":["### Обучение моделей"]},{"cell_type":"markdown","metadata":{"id":"UzP9AdAwZV5s"},"source":["Следующая функция будет использоваться для обучения модели. Аргументы:  \n","* model $-$ нейросеть\n","* loss $-$ оптимизируемая функция (criterion, cost function, objective)\n","* optimizer $-$ оптимизационный алгоритм\n","* scheduler $-$ политика изменения learning_rate\n","* num_epochs $-$ количество итераций обучения"]},{"cell_type":"code","metadata":{"id":"QkMmJ7W-pjtA"},"source":["from catalyst import dl, metrics\n","\n","class ImgRunner(dl.Runner):\n","\n","    def predict_batch(self, batch):\n","        # model inference step\n","        return self.model(batch[0].to(self.device).view(batch[0].size(0), -1))\n","\n","    def _handle_batch(self, batch):\n","        # model train/valid step\n","        x, y = batch\n","        self.input = {\"targets\": y}\n","        y_hat = self.model(x)\n","        self.output = {\"logits\": y_hat}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Afrq3SA1ZV53"},"source":["### Задание"]},{"cell_type":"markdown","metadata":{"id":"kNCYHC8oZV53"},"source":["Для каждой из следующих нейросетей:\n","* **AlexNet** (уже сделано в примере)\n","* **VGG16**\n","* **Inception_v3**\n","\n","Напишите код и выведите результат (график лосса, accuracy и вывод примера классификации картинок с визализацией (с помощью функции `vizualize_model()`)) для трёх способов:\n","* Использование готовой нейросети **\"из коробки\"**\n","* Использование нейросети как **Feature Extractor**\n","* **Fine Tuning** нейросети\n","\n","Для каждого пункта нужно:\n","* сделать с сетью то, что нужно в пункте (\"из коробки\", FE или FT)\n","* вывести график loss'а на обучающей и на валидационной выборке\n","* вывести качество модели (accuracy) на валидационной (тестовой) выборке\n","* (по желанию) использовать функцию visualize_model()"]},{"cell_type":"markdown","metadata":{"id":"8XzWmgE7ZV54"},"source":["### AlexNet"]},{"cell_type":"markdown","metadata":{"id":"g6zW24cSZV56"},"source":["*ПРИМЕЧАНИЕ: Здесь не выведены графики loss'а и не использована visualize_model(). От Вас это ожидается.*"]},{"cell_type":"markdown","metadata":{"id":"FmLx0a_uZV56"},"source":["Загрузка модели:"]},{"cell_type":"code","metadata":{"id":"1mHbrvXAZV57"},"source":["model = models.alexnet(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W_g9XqLsZV5-"},"source":["Посмотрим, что внутри:"]},{"cell_type":"code","metadata":{"id":"N-OLqslsZV6A"},"source":["model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O9LYMESWZV6E"},"source":["Видим, что на вход классификатору (classifier) подаётся *9216 признаков*. Это и будет размер входа для нашего нового классификатора."]},{"cell_type":"markdown","metadata":{"id":"FA5qB523ZV6G"},"source":["* **Fine Tuning** способ"]},{"cell_type":"markdown","metadata":{"id":"AxucpA3FZV6H"},"source":["Сконфигурируем - изменим FC-слой и зададим *cost function* и *оптимизирующий алгоритм*:"]},{"cell_type":"markdown","metadata":{"id":"6JKPZYgVZV6J"},"source":["(*по умолчанию backpropagation распространяется на все слои, поэтому здесь мы только заменяем FC-слой на свой классификатор*)"]},{"cell_type":"code","metadata":{"id":"iGw8dN6QwWHI"},"source":["!rm -rf logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppIGmkz4ZV6K"},"source":["# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n","num_features = 4096\n","# Заменяем Fully-Connected слой на наш линейный классификатор\n","model.classifier[6] = nn.Linear(num_features, 2)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_MsDT40aSg1n"},"source":["%reload_ext tensorboard\n","%tensorboard --logdir logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DXDZK7JVZV6X","scrolled":true},"source":["runner = ImgRunner()\n","runner.train(\n","    model=model,\n","    optimizer=optimizer,\n","    criterion=nn.CrossEntropyLoss(),\n","    callbacks=[\n","        dl.CriterionCallback(),\n","        dl.OptimizerCallback(),\n","        dl.AccuracyCallback()\n","    ],\n","    loaders=loaders,\n","    num_epochs=10,\n","    verbose=True,\n","    main_metric=\"accuracy01\",\n","    minimize_metric=False,\n","    logdir=\"logs/alexnet\"\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vyM6SLNZZV6g"},"source":["* **Feature Extractor** способ:"]},{"cell_type":"code","metadata":{"id":"81XVFTJiZV6h"},"source":["model_extractor = models.alexnet(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6XUzgLSlZV6m"},"source":["Помним, что по-умолчанию все слои нейросети обучаются заново:"]},{"cell_type":"code","metadata":{"id":"8kiGUDNqZV6n"},"source":["for param in model_extractor.parameters():\n","    print(param.requires_grad)\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOTXa28JZV6s"},"source":["Сделаем так, чтобы на них *не распространялся backpropagation* (заморозим их), и подменим классификатор (ведь старый уже с весами для ImageNet'а)."]},{"cell_type":"code","metadata":{"id":"K7rW4vKaZV6u"},"source":["# замораживаем параметры (веса)\n","for param in model_extractor.parameters():\n","    param.requires_grad = False\n","\n","# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n","num_features = 4096\n","# Заменяем Fully-Connected слой на наш линейный классификатор\n","model_extractor.classifier[6] = nn.Linear(num_features, 2)\n","\n","# Обучаем только классификатор\n","optimizer = optim.Adam(model_extractor.classifier[6].parameters(), lr=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVL7TjRIZV6z"},"source":["runner = ImgRunner()\n","\n","runner.train(\n","    model=model_extractor,\n","    optimizer=optimizer,\n","    criterion=nn.CrossEntropyLoss(),\n","    callbacks=[\n","        dl.CriterionCallback(),\n","        dl.OptimizerCallback(),\n","        dl.AccuracyCallback()\n","    ],\n","    loaders=loaders,\n","    num_epochs=10,\n","    verbose=True,\n","    main_metric=\"accuracy01\",\n","    minimize_metric=False,\n","    logdir=\"logs/alexnet_freeze\"\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RmehLHv9Sg3d"},"source":["* **Смешанный** способ:\n","Мы будем обучать не только последний **fully connected** слой, но и несколько предпоследних"]},{"cell_type":"code","metadata":{"id":"NAcI23-OSg3e"},"source":["model_mixed = models.alexnet(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"69YQJd2hzzi7"},"source":["model_mixed"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TG7n2z9bSg3h"},"source":["from itertools import chain\n","\n","layers_to_unfreeze = 5\n","\n","# Выключаем подсчет градиентов для слоев, которые не будем обучать\n","for param in model_mixed.features[:-layers_to_unfreeze].parameters():\n","    param.requires_grad = False\n","\n","# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n","num_features = 4096\n","# Заменяем Fully-Connected слой на наш линейный классификатор\n","model_mixed.classifier[6] = nn.Linear(num_features, 2)\n","\n","# Обучаем последние layers_to_unfreeze слоев из сверточной части и fully connected слой\n","# parameters() возвращает просто список тензоров парамтеров, поэтому два таких списка можно сложить\n","optimizer = torch.optim.Adam(\n","    chain(\n","        list(model_mixed.features.parameters())[-layers_to_unfreeze:],\n","        model_mixed.classifier.parameters()\n","    ),\n","    lr=1e-4,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"908lTwBoSg3n","scrolled":true},"source":["runner = ImgRunner()\n","\n","runner.train(\n","    model=model_mixed,\n","    optimizer=optimizer,\n","    criterion=nn.CrossEntropyLoss(),\n","    callbacks=[\n","        dl.CriterionCallback(),\n","        dl.OptimizerCallback(),\n","        dl.AccuracyCallback()\n","    ],\n","    loaders=loaders,\n","    num_epochs=10,\n","    verbose=True,\n","    main_metric=\"accuracy01\",\n","    minimize_metric=False,\n","    logdir=\"logs/alexnet_mixed\"\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o3GXxu9u4Ssj"},"source":["### Бонус\n","\n","Существует еще один интересный способ. Мы не хотим, чтобы ядра в свертках сильно менялись во время обучения, а еще мы знаем, что чем меньше lr, тем меньше изменения. Давайте уменьшим lr на feature extractor-е! Разберемся как это сделать..."]},{"cell_type":"code","metadata":{"id":"YyphERHE5SER"},"source":["model_mixed_lr = models.alexnet(pretrained=True)\n","\n","# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n","num_features = 4096\n","# Заменяем Fully-Connected слой на наш линейный классификатор\n","model_mixed.classifier[6] = nn.Linear(num_features, 2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-yJuZbE5fLT"},"source":["optimizer = torch.optim.Adam(\n","    (\n","        {\n","            \"params\": model_mixed_lr.features.parameters(),\n","            \"lr\": 1e-6,\n","        },\n","        {\n","            \"params\": model_mixed_lr.classifier.parameters(),\n","        }\n","     ),\n","     lr=1e-4\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8jQOU2sP6qYf"},"source":["runner = ImgRunner()\n","\n","runner.train(\n","    model=model_mixed_lr,\n","    optimizer=optimizer,\n","    criterion=nn.CrossEntropyLoss(),\n","    callbacks=[\n","        dl.CriterionCallback(),\n","        dl.OptimizerCallback(),\n","        dl.AccuracyCallback()\n","    ],\n","    loaders=loaders,\n","    num_epochs=10,\n","    verbose=True,\n","    main_metric=\"accuracy01\",\n","    minimize_metric=False,\n","    logdir=\"logs/alexnet_mixed_lr\"\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"90JYIt39ZV7W"},"source":["### Другие, более современные нейросети"]},{"cell_type":"markdown","metadata":{"id":"YLb_VQ-nZV7Y"},"source":["### ResNet 18"]},{"cell_type":"code","metadata":{"id":"UQDYaJdJ6iPf"},"source":["models.resnet18(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HrmyWuu-ZV7Z"},"source":["# Ваш код здесь\n","model_extractor = models.resnet18(pretrained=True)\n","\n","# замораживаем параметры (веса)\n","for param in model_extractor.parameters():\n","    param.requires_grad = False\n","\n","# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n","num_features = 512\n","# Заменяем Fully-Connected слой на наш линейный классификатор\n","model_extractor.fc = nn.Linear(num_features, 2)\n","\n","# Обучаем только классификатор\n","optimizer = optim.Adam(model_extractor.fc.parameters(), lr=1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5b72ftgCSg44","scrolled":true},"source":["runner = ImgRunner()\n","\n","runner.train(\n","    model=model_extractor,\n","    optimizer=optimizer,\n","    criterion=nn.CrossEntropyLoss(),\n","    callbacks=[\n","        dl.CriterionCallback(),\n","        dl.OptimizerCallback(),\n","        dl.AccuracyCallback()\n","    ],\n","    loaders=loaders,\n","    num_epochs=10,\n","    verbose=True,\n","    main_metric=\"accuracy01\",\n","    minimize_metric=False,\n","    logdir=\"logs/resnet\",\n","    load_best_on_end=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jrgVXFdY9-Ls"},"source":["# замораживаем параметры (веса)\n","for param in model_extractor.parameters():\n","    param.requires_grad = True\n","\n","optimizer = optim.Adam(model_extractor.parameters(), lr=1e-4)\n","\n","runner = ImgRunner()\n","\n","runner.train(\n","    model=model_extractor,\n","    optimizer=optimizer,\n","    criterion=nn.CrossEntropyLoss(),\n","    callbacks=[\n","        dl.CriterionCallback(),\n","        dl.OptimizerCallback(),\n","        dl.AccuracyCallback()\n","    ],\n","    loaders=loaders,\n","    num_epochs=10,\n","    verbose=True,\n","    main_metric=\"accuracy01\",\n","    minimize_metric=False,\n","    logdir=\"logs/resnet_step2\",\n","    load_best_on_end=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c57p6EIi6qv2"},"source":["\n","<h2 style=\"text-align: center;\"><b>Полезные ссылки</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"8CvOZffV6qv2"},"source":["1). *cs231n: http://cs231n.github.io/transfer-learning/*\n","\n","2). *Туториал на PyTorch Tutorials: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial*\n","\n","3). *Статья на Medium про TL в PyTorch: https://medium.com/@14prakash/almost-any-image-classification-problem-using-pytorch-i-am-in-love-with-pytorch-26c7aa979ec4*  "]}]}